{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/afarhan/opt/anaconda3/envs/dynamic_embedding/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "# The version of the tensorflow is v-2.0. \n",
    "# But I am using commands/libraries from v-1.0. So disabling the v2 behavior.\n",
    "tf.disable_v2_behavior()\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_lm import BasicNeuralLM\n",
    "from utils import DataLoader, SmallConfig, MediumConfig, LargeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SmallConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader('toy.txt', conf.batch_size, conf.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicNeuralLM(conf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<basic_lm.BasicNeuralLM at 0x13f9b6a20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/afarhan/UTEP/Workspace/MachineLearning/Embedding-Models/Neural_Language_Model_Bengio_2003/basic_lm.py:66: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, seed, max_seq_len=45):\n",
    "    '''\n",
    "    :param model: model object which has had model.build_graph() already run\n",
    "    :param seed: list of num_steps strings\n",
    "    :return: list of strings\n",
    "    '''\n",
    "    assert len(seed) == model.conf.num_steps, \"Error: seed is of incorrect length, must provide list of {} strings\".format(model.conf.num_steps)\n",
    "    seq = []\n",
    "    for w in seed:\n",
    "        if w not in model.data.vocab:\n",
    "            seq.append(model.data.word2idx['<UNK>'])\n",
    "        else:\n",
    "            seq.append(model.data.word2idx[w])\n",
    "\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "        current = seq[-1]\n",
    "        while model.data.idx2word[current] != '#' and len(seq) <= max_seq_len:\n",
    "            # Lazy solution here where we just pass the input sequence and a matrix of zeros so its the right shape\n",
    "            input_matrix = np.zeros([model.conf.batch_size, model.conf.num_steps])\n",
    "            input_matrix[0, :] = seq[-model.conf.num_steps:]\n",
    "            feed_dict = {model.train_input: input_matrix}\n",
    "            current = sess.run(tf.argmax(tf.nn.softmax(model.logits), axis=1), feed_dict=feed_dict)\n",
    "            seq.append(current[0])\n",
    "            current = current[0]\n",
    "\n",
    "    return [model.data.idx2word[idx] for idx in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, visualize_embeddings=True):\n",
    "    '''\n",
    "    :param model: model object which has had model.build_graph() already run\n",
    "    :param num_train_steps: number of steps to train model\n",
    "    :return: n/a\n",
    "    '''\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "\n",
    "        #if ckpt and ckpt.model_checkpoint_path:\n",
    "        #    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "        initial_step = model.global_step.eval()\n",
    "        for i in range(initial_step + model.conf.num_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            # Training loop for epoch\n",
    "            train_loss = 0.0\n",
    "            j = 0\n",
    "            print(sess.run(model.global_step))\n",
    "            for batch_X, batch_y in model.data.load_batches():\n",
    "                feed_dict = {model.train_input: batch_X, model.train_labels: batch_y}\n",
    "                loss_batch, _ = sess.run([model.loss, model.optimizer],\n",
    "                                                feed_dict=feed_dict)\n",
    "                train_loss += loss_batch\n",
    "                epoch_loss += loss_batch\n",
    "                j += 1\n",
    "                if (j + 1) % model.conf.skip_step == 0:\n",
    "                    train_loss = sum(train_loss)\n",
    "                    print('Average loss at step {}: {:5.1f}'.format(j, train_loss / model.conf.skip_step))\n",
    "                    train_loss = 0.0\n",
    "                    saver.save(sess, 'checkpoints/language-model', j)\n",
    "            # Validation loop for epoch\n",
    "            val_loss = 0.0\n",
    "            for batch_X, batch_y in model.data.load_batches(kind='validation'):\n",
    "                feed_dict = {model.train_input: batch_X, model.train_labels: batch_y}\n",
    "                loss_batch, _ = sess.run([model.loss, model.optimizer],\n",
    "                                                  feed_dict=feed_dict)\n",
    "                val_loss += loss_batch\n",
    "            print(\"Average validation set loss: {}\".format(sum(val_loss) / model.data.num_batches[\"validation\"]))\n",
    "            print(\"Epoch {} complete with average error of {} on training set\".format(i+1, sum(epoch_loss) / model.data.num_batches[\"train\"]))\n",
    "            print(' '.join(generate_sequence(model, ['#']*(data.window-1)+['i'])))\n",
    "            print(' '.join(['-']*35))\n",
    "\n",
    "        if visualize_embeddings:\n",
    "            final_embed_matrix = sess.run(model.embed_matrix)\n",
    "            embedding_var = tf.Variable(final_embed_matrix[:1000], name='embedding')\n",
    "            sess.run(embedding_var.initializer)\n",
    "\n",
    "            config = projector.ProjectorConfig()\n",
    "            summary_writer = tf.summary.FileWriter('processed')\n",
    "\n",
    "            embedding = config.embeddings.add()\n",
    "            embedding.tensor_name = embedding_var.name\n",
    "\n",
    "            embedding.metadata_path = 'processed/vocab_1000.tsv'\n",
    "            projector.visualize_embeddings(summary_writer, config)\n",
    "            saver_embed = tf.train.Saver([embedding_var])\n",
    "            saver_embed.save(sess, 'processed/model3.ckpt', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Average loss at step 1: 402.4\n",
      "Average loss at step 3: 902.8\n",
      "Average validation set loss: 870.1387128829956\n",
      "Epoch 1 complete with average error of 879.9116296768188 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i , , , , , <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "5\n",
      "Average loss at step 1: 201.8\n",
      "Average loss at step 3: 333.6\n",
      "Average validation set loss: 298.18833319004625\n",
      "Epoch 2 complete with average error of 344.33881920576096 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i reason one of necessary although well socialist objectives european actually , sectors supported of up opportunities , , , , , of times occurred well debate money european few by amendments information of method towards , capital refer <UNK> including\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "10\n",
      "Average loss at step 1:  85.8\n",
      "Average loss at step 3: 127.0\n",
      "Average validation set loss: 90.70453641796485\n",
      "Epoch 3 complete with average error of 129.58728187531233 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i reason , , certainly population taxpayer , , is <UNK> , , , execution , , , be industrial , , is half , , is 1997 , , is 1997 , , is 1997 , , is 1997 ,\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "15\n",
      "Average loss at step 1:  18.7\n",
      "Average loss at step 3:  47.9\n",
      "Average validation set loss: 29.52523354103323\n",
      "Epoch 4 complete with average error of 39.140363729558885 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i reason the of crucial certainly give internal , responsible , whose , of , of , of , of , of , of , of , of , of , of , of , of , of , of ,\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "20\n",
      "Average loss at step 1:  11.0\n",
      "Average loss at step 3:  24.7\n",
      "Average validation set loss: 10.920260367682204\n",
      "Epoch 5 complete with average error of 19.762594068422914 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i reason of , certainly amongst to , of , whose , of , of , of , of , of , of , of , of , of , of , of , of , of , of , of\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "25\n",
      "Average loss at step 1:  13.0\n",
      "Average loss at step 3:  11.6\n",
      "Average validation set loss: 4.273288713651709\n",
      "Epoch 6 complete with average error of 13.206865469925106 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion request <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "30\n",
      "Average loss at step 1:   2.4\n",
      "Average loss at step 3:   5.2\n",
      "Average validation set loss: 3.4396754328045063\n",
      "Epoch 7 complete with average error of 4.7446835692971945 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this <UNK> <UNK> <UNK> the <UNK> extremely the really your <UNK> and the island mentioned , manner the of commission in <UNK> the 1997 failure maintaining the of never a member the of businesses issues the though said\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "35\n",
      "Average loss at step 1:   1.3\n",
      "Average loss at step 3:   3.6\n",
      "Average validation set loss: 2.3383038690080866\n",
      "Epoch 8 complete with average error of 2.947643048595637 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of should , <UNK> the , <UNK> , the , <UNK> , the , <UNK> , the , <UNK> , the , <UNK> , the , <UNK> ,\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "40\n",
      "Average loss at step 1:   1.0\n",
      "Average loss at step 3:   2.5\n",
      "Average validation set loss: 2.0674200924113393\n",
      "Epoch 9 complete with average error of 2.22589323669672 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "45\n",
      "Average loss at step 1:   0.9\n",
      "Average loss at step 3:   2.1\n",
      "Average validation set loss: 1.8257834509422537\n",
      "Epoch 10 complete with average error of 1.851917285937816 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of should , <UNK> the , <UNK> of the , in , , <UNK> the , <UNK> , the , <UNK> , the , <UNK> , the ,\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "50\n",
      "Average loss at step 1:   0.7\n",
      "Average loss at step 3:   1.9\n",
      "Average validation set loss: 1.6724095460958779\n",
      "Epoch 11 complete with average error of 1.6650471235625446 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "55\n",
      "Average loss at step 1:   0.7\n",
      "Average loss at step 3:   1.7\n",
      "Average validation set loss: 1.5516699792351574\n",
      "Epoch 12 complete with average error of 1.5366676305420697 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "60\n",
      "Average loss at step 1:   0.6\n",
      "Average loss at step 3:   1.6\n",
      "Average validation set loss: 1.452567094587721\n",
      "Epoch 13 complete with average error of 1.433997397776693 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "65\n",
      "Average loss at step 1:   0.6\n",
      "Average loss at step 3:   1.5\n",
      "Average validation set loss: 1.3687030030996539\n",
      "Epoch 14 complete with average error of 1.3482967973686755 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "70\n",
      "Average loss at step 1:   0.6\n",
      "Average loss at step 3:   1.4\n",
      "Average validation set loss: 1.2962210596015211\n",
      "Epoch 15 complete with average error of 1.274931963533163 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "75\n",
      "Average loss at step 1:   0.5\n",
      "Average loss at step 3:   1.3\n",
      "Average validation set loss: 1.2325765093264636\n",
      "Epoch 16 complete with average error of 1.2109801908954978 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "80\n",
      "Average loss at step 1:   0.5\n",
      "Average loss at step 3:   1.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation set loss: 1.1759959872579202\n",
      "Epoch 17 complete with average error of 1.154503178782761 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "85\n",
      "Average loss at step 1:   0.5\n",
      "Average loss at step 3:   1.2\n",
      "Average validation set loss: 1.1252310938434675\n",
      "Epoch 18 complete with average error of 1.1040675123222172 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "90\n",
      "Average loss at step 1:   0.5\n",
      "Average loss at step 3:   1.2\n",
      "Average validation set loss: 1.079335284710396\n",
      "Epoch 19 complete with average error of 1.058633295353502 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "95\n",
      "Average loss at step 1:   0.5\n",
      "Average loss at step 3:   1.1\n",
      "Average validation set loss: 1.0375654599338304\n",
      "Epoch 20 complete with average error of 1.017415648093447 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "100\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   1.1\n",
      "Average validation set loss: 0.9971759481704794\n",
      "Epoch 21 complete with average error of 0.9789525317028165 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "105\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   1.0\n",
      "Average validation set loss: 0.9637406975380145\n",
      "Epoch 22 complete with average error of 0.9457888186443597 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "110\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   1.0\n",
      "Average validation set loss: 0.932710356079042\n",
      "Epoch 23 complete with average error of 0.9151220419444144 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "115\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   1.0\n",
      "Average validation set loss: 0.903822914493503\n",
      "Epoch 24 complete with average error of 0.886648581828922 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "120\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   0.9\n",
      "Average validation set loss: 0.876837418647483\n",
      "Epoch 25 complete with average error of 0.8601206787861884 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "125\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   0.9\n",
      "Average validation set loss: 0.8515878218458965\n",
      "Epoch 26 complete with average error of 0.8353215116076171 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "130\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   0.9\n",
      "Average validation set loss: 0.827886875369586\n",
      "Epoch 27 complete with average error of 0.8120815888978541 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "135\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   0.9\n",
      "Average validation set loss: 0.8055653035989963\n",
      "Epoch 28 complete with average error of 0.7902307391632348 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "140\n",
      "Average loss at step 1:   0.4\n",
      "Average loss at step 3:   0.8\n",
      "Average validation set loss: 0.7845327105897013\n",
      "Epoch 29 complete with average error of 0.769661768572405 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "145\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.8\n",
      "Average validation set loss: 0.7646665596112143\n",
      "Epoch 30 complete with average error of 0.7502363091334701 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "150\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.8\n",
      "Average validation set loss: 0.7458518095663749\n",
      "Epoch 31 complete with average error of 0.73186697345227 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "155\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.8\n",
      "Average validation set loss: 0.7280191949103028\n",
      "Epoch 32 complete with average error of 0.7144473490770906 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "160\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.8\n",
      "Average validation set loss: 0.7110873960773461\n",
      "Epoch 33 complete with average error of 0.6979261166416109 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "165\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.7\n",
      "Average validation set loss: 0.694982943998184\n",
      "Epoch 34 complete with average error of 0.6822090588975698 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "170\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.7\n",
      "Average validation set loss: 0.6796337051782757\n",
      "Epoch 35 complete with average error of 0.6672463847789913 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "175\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.7\n",
      "Average validation set loss: 0.6650024533446413\n",
      "Epoch 36 complete with average error of 0.6529823103919625 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "180\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.7\n",
      "Average validation set loss: 0.6510362404223997\n",
      "Epoch 37 complete with average error of 0.6393615789711475 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "185\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.7\n",
      "Average validation set loss: 0.637665783520788\n",
      "Epoch 38 complete with average error of 0.6263399650342762 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "190\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.7\n",
      "Average validation set loss: 0.6248853401339147\n",
      "Epoch 39 complete with average error of 0.6138759604655206 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "195\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.7\n",
      "Average validation set loss: 0.6126303431810811\n",
      "Epoch 40 complete with average error of 0.6019369838759303 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "200\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.6001011655898765\n",
      "Epoch 41 complete with average error of 0.5901947123929858 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "205\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5893335386062972\n",
      "Epoch 42 complete with average error of 0.5796417235396802 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "210\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5789669675577898\n",
      "Epoch 43 complete with average error of 0.5694879908114672 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "215\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5689755476778373\n",
      "Epoch 44 complete with average error of 0.5597036783583462 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "220\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5593343673972413\n",
      "Epoch 45 complete with average error of 0.5502764689736068 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "225\n",
      "Average loss at step 1:   0.3\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5500373777176719\n",
      "Epoch 46 complete with average error of 0.5411832805257291 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "230\n",
      "Average loss at step 1:   0.2\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5410526852647308\n",
      "Epoch 47 complete with average error of 0.532404717290774 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "235\n",
      "Average loss at step 1:   0.2\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5323690680379514\n",
      "Epoch 48 complete with average error of 0.5239230452571064 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "240\n",
      "Average loss at step 1:   0.2\n",
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5239760635304265\n",
      "Epoch 49 complete with average error of 0.515724774915725 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "245\n",
      "Average loss at step 1:   0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 3:   0.6\n",
      "Average validation set loss: 0.5158542545395903\n",
      "Epoch 50 complete with average error of 0.5077948444522917 on training set\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/language-model-3\n",
      "# # # # # i opinion opinion this second would <UNK> the failure parliament in hence , of <UNK> , <UNK> , <UNK> , the , the , the , the , the , the , the , the , the , the , the\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'projector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4c7aaa9735fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-3034b573ec95>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, visualize_embeddings)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProjectorConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0msummary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'projector' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
